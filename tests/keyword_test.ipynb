{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad4bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_case_path = 'C:\\\\Users\\\\me\\\\nlp\\\\NLP-Case\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a87075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(nlp_case_path)\n",
    "from TextProcessor import TextProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07befcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import nltk\n",
    "cnn = nlp_case_path + 'data\\\\cnn.csv'\n",
    "database = []\n",
    "y = []\n",
    "with open(cnn, 'r', encoding = 'utf-8') as textfile:\n",
    "    csvreader = csv.reader(textfile, delimiter=',', quotechar='\"')\n",
    "    i = 0\n",
    "    for row in csvreader:\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "            \n",
    "        if len(row[2]) == 0:\n",
    "            continue\n",
    "        y.append(ast.literal_eval(row[1]))\n",
    "        database.append(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af62d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hlcsr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hlcsr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hlcsr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hlcsr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd31c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story highlights Don't be fooled by the word \"energy\"Some energy bars contain as much saturated fat as a Snickers bar(CNN) Energy bars are a convenient source of nutrition and come in a wide variety of flavors to satisfy different palates.\n",
      "But, like many foods in a specific category, not all energy bars are created equal.\n",
      "For example, some bars covered in chocolate contain as much saturated fat as a Snickers bar; others contain almost as much sugar.\n",
      "Energy bars containing mostly fruit and nuts can serve as satisfying snacks.\n",
      "In general, try to aim for bars with less than 3 grams of saturated fat and at least 4 grams of fiber.\n",
      "======\n",
      "Story highlights Don be fooled by the word energy Some energy bars contain as much saturated fat as Snickers bar CNN Energy bars are convenient source of nutrition and come in wide variety of flavors to satisfy different palates But like many foods in specific category not all energy bars are created equal For example some bars covered in chocolate contain as much saturated fat as Snickers bar others contain almost as much sugar Energy bars containing mostly fruit and nuts can serve as satisfying snacks In general try to aim for bars with less than grams of saturated fat and at least grams of fiber\n",
      "======\n",
      "['story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'general', 'try', 'aim', 'bar', 'le', 'gram', 'saturated', 'fat', 'least', 'gram', 'fiber']\n"
     ]
    }
   ],
   "source": [
    "print(database[0])\n",
    "print('======')\n",
    "filtered = TextProcessor.filter(database)\n",
    "print(filtered[0])\n",
    "print('======')\n",
    "preprocessed = TextProcessor.preprocess(filtered, use_tag_prediction = False)\n",
    "print(preprocessed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54491691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERALL:\n",
      "Recall,  0.3515015958558589\n",
      "Precision  0.3477508792131094\n"
     ]
    }
   ],
   "source": [
    "keywords = TextProcessor.extract_keywords(preprocessed, 0.333, relative = True)\n",
    "sum_recall = 0.\n",
    "sum_precision = 0.\n",
    "for i in range(len(keywords)):\n",
    "    precision, recall = TextProcessor.compare_keywords(keywords[i], y[i])\n",
    "    #print(precision, recall)\n",
    "    sum_recall += recall\n",
    "    sum_precision += precision\n",
    "    \n",
    "print('OVERALL:')\n",
    "print('Recall, ', sum_recall/len(keywords))\n",
    "print('Precision ', sum_precision/len(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nlp_case'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-41792971b0c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnlp_case\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextRank_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextRank_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnlp_case\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTfidf_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidf_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m text = '''We consider the potential density of rational points on an algebraic variety\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nlp_case'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}